{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                        listing_url       scrape_id last_scraped  \\\n",
      "0  3109  https://www.airbnb.com/rooms/3109  20241206031559   2024-12-07   \n",
      "1  5396  https://www.airbnb.com/rooms/5396  20241206031559   2024-12-09   \n",
      "2  7397  https://www.airbnb.com/rooms/7397  20241206031559   2024-12-08   \n",
      "3  7964  https://www.airbnb.com/rooms/7964  20241206031559   2024-12-09   \n",
      "4  9359  https://www.airbnb.com/rooms/9359  20241206031559   2024-12-09   \n",
      "\n",
      "            source                                             name  \\\n",
      "0      city scrape                                     zen and calm   \n",
      "1      city scrape     Your perfect Paris studio on Île Saint-Louis   \n",
      "2      city scrape                 MARAIS - 2ROOMS APT - 2/4 PEOPLE   \n",
      "3  previous scrape                     Sunny apartment with balcony   \n",
      "4      city scrape  Cozy, Central Paris: WALK or VELIB EVERYWHERE !   \n",
      "\n",
      "                                         description  \\\n",
      "0  Lovely Appartment with one bedroom with a Quee...   \n",
      "1  NEW SOFA-BED SINCE JUNE 2023, Please disregard...   \n",
      "2          VERY CONVENIENT, WITH THE BEST LOCATION !   \n",
      "3  We are renting our a spacious, sunny fully fur...   \n",
      "4  Location! Location! Location! Just bring your ...   \n",
      "\n",
      "                               neighborhood_overview  \\\n",
      "0  Good restaurants<br />very close the Montparna...   \n",
      "1  You are within walking distance to the Louvre,...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                         picture_url  host_id  ...  \\\n",
      "0  https://a0.muscache.com/pictures/miso/Hosting-...     3631  ...   \n",
      "1  https://a0.muscache.com/pictures/52413/f9bf76f...     7903  ...   \n",
      "2  https://a0.muscache.com/pictures/67928287/330b...     2626  ...   \n",
      "3  https://a0.muscache.com/pictures/miso/Hosting-...    22155  ...   \n",
      "4  https://a0.muscache.com/pictures/c2965945-061f...    28422  ...   \n",
      "\n",
      "  review_scores_communication review_scores_location review_scores_value  \\\n",
      "0                        5.00                   5.00                5.00   \n",
      "1                        4.85                   4.96                4.59   \n",
      "2                        4.89                   4.94                4.74   \n",
      "3                        5.00                   5.00                5.00   \n",
      "4                         NaN                    NaN                 NaN   \n",
      "\n",
      "                                             license instant_bookable  \\\n",
      "0                                      7511409139079                t   \n",
      "1                                      7510402838018                f   \n",
      "2                                      7510400829623                f   \n",
      "3                                      7510903576564                f   \n",
      "4  Available with a mobility lease only (\"bail mo...                f   \n",
      "\n",
      "  calculated_host_listings_count calculated_host_listings_count_entire_homes  \\\n",
      "0                              1                                           1   \n",
      "1                              1                                           1   \n",
      "2                              2                                           2   \n",
      "3                              1                                           1   \n",
      "4                              1                                           1   \n",
      "\n",
      "  calculated_host_listings_count_private_rooms  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "3                                            0   \n",
      "4                                            0   \n",
      "\n",
      "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
      "0                                           0              0.05  \n",
      "1                                           0              2.26  \n",
      "2                                           0              2.20  \n",
      "3                                           0              0.03  \n",
      "4                                           0               NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FranckPERSONNE\\AppData\\Local\\Temp\\ipykernel_31512\\901047985.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['price'] = df_cleaned['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Entire rental unit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m impute_with_random_forest(df_cleaned, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccommodates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbedrooms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_nights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximum_nights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_scores_rating\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Appliquer RandomForest pour l'imputation des variables catégorielles \"property_type\" et \"room_type\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mimpute_with_random_forest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproperty_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccommodates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbedrooms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminimum_nights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximum_nights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumber_of_reviews\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_scores_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m impute_with_random_forest(df_cleaned, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom_type\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccommodates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbedrooms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_nights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximum_nights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_scores_rating\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 7. Conversion des types de données (en particulier les variables catégorielles)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36mimpute_with_random_forest\u001b[1;34m(df_cleaned, target_column, features)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Entraînement d'un modèle RandomForest\u001b[39;00m\n\u001b[0;32m     50\u001b[0m rf_regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mrf_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Prédiction des valeurs manquantes\u001b[39;00m\n\u001b[0;32m     54\u001b[0m X_missing \u001b[38;5;241m=\u001b[39m df_missing[features]\n",
      "File \u001b[1;32mc:\\Users\\FranckPERSONNE\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\FranckPERSONNE\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:422\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y_class_weight(y)\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[1;32m--> 422\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOUBLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expanded_class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Entire rental unit'"
     ]
    }
   ],
   "source": [
    "# 1. Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 2. Chargement du dataset\n",
    "file_path = 'listings.csv'  # Remplacer par le chemin de votre fichier\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Affichage des premières lignes pour vérifier\n",
    "print(df.head())\n",
    "\n",
    "# 3. Sélection des colonnes pertinentes\n",
    "colonnes_pertinentes = [\n",
    "    'price', 'property_type', 'room_type', 'accommodates', 'bedrooms', 'beds',\n",
    "    'bathrooms_text', 'neighbourhood_cleansed', 'host_is_superhost',\n",
    "    'minimum_nights', 'maximum_nights', 'number_of_reviews', 'review_scores_rating',\n",
    "    'instant_bookable'\n",
    "]\n",
    "df = df[colonnes_pertinentes]\n",
    "\n",
    "# 4. Suppression des doublons\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# 5. Nettoyage des données\n",
    "# Nettoyage de la colonne \"price\" pour enlever les symboles monétaires et convertir en numérique\n",
    "df_cleaned['price'] = df_cleaned['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# 6. Gestion des valeurs manquantes\n",
    "# Imputation avec RandomForest pour les variables numériques\n",
    "def impute_with_random_forest(df_cleaned, target_column, features):\n",
    "    # Séparation entre données avec et sans valeur manquante pour la cible\n",
    "    df_train = df_cleaned.dropna(subset=[target_column])\n",
    "    df_missing = df_cleaned[df_cleaned[target_column].isna()]\n",
    "\n",
    "    # Sélection des variables explicatives (features)\n",
    "    X_train = df_train[features]\n",
    "    y_train = df_train[target_column]\n",
    "\n",
    "    # Entraînement d'un modèle RandomForest\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Prédiction des valeurs manquantes\n",
    "    X_missing = df_missing[features]\n",
    "    predicted_values = rf_regressor.predict(X_missing)\n",
    "\n",
    "    # Imputation des valeurs manquantes\n",
    "    df_cleaned.loc[df_cleaned[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "# Appliquer RandomForest pour l'imputation de valeurs manquantes dans \"price\"\n",
    "df_cleaned = impute_with_random_forest(df_cleaned, 'price', ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews', 'review_scores_rating'])\n",
    "\n",
    "# Appliquer RandomForest pour l'imputation des variables catégorielles \"property_type\" et \"room_type\"\n",
    "df_cleaned = impute_with_random_forest(df_cleaned, 'property_type', ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews', 'review_scores_rating'])\n",
    "df_cleaned = impute_with_random_forest(df_cleaned, 'room_type', ['accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews', 'review_scores_rating'])\n",
    "\n",
    "# 7. Conversion des types de données (en particulier les variables catégorielles)\n",
    "df_cleaned['host_is_superhost'] = df_cleaned['host_is_superhost'].map({'t': 'Oui', 'f': 'Non'}).astype('category')\n",
    "df_cleaned['instant_bookable'] = df_cleaned['instant_bookable'].map({'t': 'Oui', 'f': 'Non'}).astype('category')\n",
    "\n",
    "# 8. Transformation de la variable \"bathrooms_text\" en valeur numérique\n",
    "df_cleaned['bathrooms_text'] = df_cleaned['bathrooms_text'].apply(lambda x: 1 if 'half' in str(x) else 0)\n",
    "\n",
    "# 9. Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "colonnes_numeriques = ['price', 'accommodates', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews', 'review_scores_rating']\n",
    "df_cleaned[colonnes_numeriques] = scaler.fit_transform(df_cleaned[colonnes_numeriques])\n",
    "\n",
    "# 10. Encodage des variables catégorielles\n",
    "# Utilisation de l'encodage One-Hot pour les variables catégorielles\n",
    "df_encoded = pd.get_dummies(df_cleaned, drop_first=True)\n",
    "\n",
    "# 11. Séparation des données en jeu d'entraînement et de test\n",
    "X = df_encoded.drop('price', axis=1)  # Variables explicatives\n",
    "y = df_encoded['price']  # Variable cible\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 12. Construction du modèle de réseau de neurones avec des ajustements supplémentaires\n",
    "model = Sequential()\n",
    "\n",
    "# Ajout de la couche d'entrée et des premières couches cachées avec Dropout\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout pour éviter le surapprentissage\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Ajout de la couche de sortie (régression donc pas d'activation)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilation du modèle avec une fonction d'optimisation améliorée\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# tf optimizer a chercher\n",
    "\n",
    "# 13. Ajout de l'early stopping pour éviter le sur-apprentissage\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 14. Entraînement du modèle avec réduction du taux d'apprentissage en cas de stagnation\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Lancer l'entraînement\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[reduce_lr, early_stop], verbose=1)\n",
    "\n",
    "# 15. Prédictions sur le jeu de test\n",
    "y_pred_nn = model.predict(X_test)\n",
    "\n",
    "# 16. Calcul du R² et de l'erreur quadratique moyenne (RMSE) pour le réseau de neurones\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "\n",
    "print(f'R² (Réseau de Neurones): {r2_nn:.4f}')\n",
    "print(f'RMSE (Réseau de Neurones): {rmse_nn:.4f}')\n",
    "\n",
    "# 17. Visualisation de l'évolution de la perte pendant l'entraînement\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Perte d\\'entraînement et de validation')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
